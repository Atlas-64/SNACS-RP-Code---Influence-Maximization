{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7f48a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import hashlib\n",
    "G = nx.read_edgelist(\"large_twitch_edges.csv\", delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6edd2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 168114 nodes and 6797557 edges\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85a3c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DegreeDiscountHeuristic(seed_num,G, p):\n",
    "    degree_dict = {}\n",
    "\n",
    "    for tuple in G.degree():\n",
    "        degree_dict[tuple[0]] = tuple[1]\n",
    "    seeds = []\n",
    "    for i in range(seed_num):\n",
    "        max_degree = max(degree_dict, key=degree_dict.get)\n",
    "        seeds.append(max_degree)\n",
    "        degree_dict.pop(max_degree)\n",
    "        for node in G.neighbors(max_degree):\n",
    "            if node in degree_dict:\n",
    "                degree_dict[node] = degree_dict[node] - 2*(i+1) - ( degree_dict[node] - i - 1)*(i+1)*p\n",
    "    return seeds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac3ce8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DegreeHeuristic(seed_num,G):\n",
    "    degree_heuristic = [node for (node, val) in sorted(G.degree(), reverse=True,key=lambda pair: pair[1])]\n",
    "    seeds = degree_heuristic[0:seed_num]\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c619212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LIRHeuristic(seed_num,G):\n",
    "    degree_dict = {}\n",
    "\n",
    "    for tuple in G.degree():\n",
    "        degree_dict[tuple[0]] = tuple[1]\n",
    "    seeds = []\n",
    "    LIR_0 = []\n",
    "    for i in range(seed_num):\n",
    "        for node in degree_dict:\n",
    "            LIR_value = 0\n",
    "            for neighbor in G.neighbors(node):\n",
    "                if degree_dict[node] < degree_dict[neighbor]:\n",
    "                    LIR_value = LIR_value + 1\n",
    "                    if LIR_value > i:\n",
    "                        break\n",
    "            if LIR_value == i:\n",
    "                LIR_0.append([node, degree_dict[node], LIR_value])\n",
    "        if len(LIR_0) >= seed_num:\n",
    "                break\n",
    "            \n",
    "    LIR_heuristic = [(node) for (node, val, lir) in sorted(sorted(LIR_0, reverse=True,key=lambda pair: pair[1]), key=lambda pair: pair[2])]\n",
    "    return LIR_heuristic[0:seed_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e0c57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IndependentCascade(G, seeds, p, perm_seed):\n",
    "    np.random.seed(perm_seed)\n",
    "    active_nodes = seeds\n",
    "    spread = []\n",
    "    while len(active_nodes) > 0:\n",
    "        curr  = active_nodes[0]\n",
    "        for  neighbor in G.neighbors(curr):\n",
    "            if neighbor not in active_nodes and neighbor not in spread:\n",
    "                if np.random.uniform(0,1) <= p:\n",
    "                    active_nodes.append(neighbor)\n",
    "        spread.append(curr)\n",
    "        active_nodes.remove(active_nodes[0])\n",
    "    return len(spread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f56c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 18, 21, 16, 20, 24, 21, 21, 24, 18, 19, 14, 21, 20, 21, 22, 20, 23, 19, 14, 18, 17, 24, 14, 12, 18, 21, 19, 21, 25, 17, 25, 21, 21, 25, 22, 26, 26, 26, 19, 21, 17, 18, 22, 24, 26, 26, 26, 25, 19, 22, 22, 16, 19, 16, 15, 15, 20, 19, 17, 21, 21, 19, 24, 19, 20, 23, 22, 22, 14, 14, 18, 25, 25, 25, 25, 19, 16, 17, 20, 18, 18, 21, 21, 21, 24, 20, 15, 22, 17, 23, 23, 25, 23, 23, 20, 23, 22, 22, 25]\n"
     ]
    }
   ],
   "source": [
    "seed_range = 100\n",
    "p = 0.002\n",
    "permutation_num = 100\n",
    "perm_seeds = []\n",
    "seed = 1000\n",
    "for i in range(permutation_num):\n",
    "    perm_seeds.append(int(hashlib.sha256(str(seed+i).encode()).hexdigest(),16)%4294967295)\n",
    "DDH_averages = []\n",
    "Degree_averages = []\n",
    "LIR_averages = []\n",
    "for i in range(seed_range):\n",
    "    seeds_DDH = DegreeDiscountHeuristic(i,G,p)\n",
    "    seeds_Degree = DegreeHeuristic(i,G)\n",
    "    seeds_LIR = LIRHeuristic(i,G)\n",
    "    seed_count_DDH = 0\n",
    "    seed_count_Degree = 0\n",
    "    seed_count_LIR = 0\n",
    "    for j in range(permutation_num):\n",
    "        seed_count_DDH = seed_count_DDH + IndependentCascade(G, seeds_DDH, p,perm_seeds[j])\n",
    "        seed_count_Degree = seed_count_Degree + IndependentCascade(G, seeds_Degree, p,perm_seeds[j])\n",
    "        seed_count_LIR = seed_count_LIR + IndependentCascade(G, seeds_LIR, p,perm_seeds[j])\n",
    "    DDH_averages.append(int(seed_count_DDH/permutation_num))\n",
    "    Degree_averages.append(int(seed_count_Degree/permutation_num))\n",
    "    LIR_averages.append(int(seed_count_LIR/permutation_num))\n",
    "print(LIR_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd999dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 18, 22, 19, 17, 21, 21, 23, 26, 25, 19, 21, 18, 20, 25, 26, 27, 25, 22, 26, 22, 25, 22, 26, 24, 26, 24, 26, 27, 24, 22, 25, 26, 24, 28, 25, 28, 27, 26, 27, 30, 28, 30, 27, 28, 29, 30, 26, 30, 29, 29, 30, 30, 29, 30, 28, 29, 31, 29, 29, 30, 32, 30, 30, 29, 28, 30, 29, 31, 30, 29, 31, 30, 32, 32, 32, 33, 31, 32, 32, 30, 34, 32, 30, 31, 34, 32, 34, 32, 33, 34, 34, 31, 31, 34, 33, 32, 33, 33, 35]\n",
      "[0, 18, 22, 19, 17, 21, 21, 23, 26, 25, 19, 21, 18, 20, 25, 26, 27, 25, 22, 26, 22, 25, 22, 26, 24, 26, 24, 26, 27, 24, 22, 25, 26, 24, 28, 25, 28, 27, 26, 27, 30, 28, 30, 27, 28, 29, 30, 26, 30, 29, 29, 30, 30, 29, 30, 28, 29, 31, 29, 29, 30, 32, 30, 30, 29, 28, 30, 29, 31, 30, 29, 31, 30, 32, 32, 32, 33, 31, 32, 32, 30, 34, 32, 30, 31, 34, 32, 34, 32, 33, 34, 34, 31, 31, 34, 33, 32, 33, 33, 35]\n",
      "[0, 18, 21, 16, 20, 24, 21, 21, 24, 18, 19, 14, 21, 20, 21, 22, 20, 23, 19, 14, 18, 17, 24, 14, 12, 18, 21, 19, 21, 25, 17, 25, 21, 21, 25, 22, 26, 26, 26, 19, 21, 17, 18, 22, 24, 26, 26, 26, 25, 19, 22, 22, 16, 19, 16, 15, 15, 20, 19, 17, 21, 21, 19, 24, 19, 20, 23, 22, 22, 14, 14, 18, 25, 25, 25, 25, 19, 16, 17, 20, 18, 18, 21, 21, 21, 24, 20, 15, 22, 17, 23, 23, 25, 23, 23, 20, 23, 22, 22, 25]\n"
     ]
    }
   ],
   "source": [
    "print(DDH_averages)\n",
    "print(Degree_averages)\n",
    "print(LIR_averages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
